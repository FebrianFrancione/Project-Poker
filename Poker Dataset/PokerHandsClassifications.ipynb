{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Poker Hands UCI Classifications\n",
    "The Poker Hands dataset is taken from here: https://archive.ics.uci.edu/ml/datasets/Poker+Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.tree \n",
    "import sklearn.ensemble\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Poker Hands Dataset from UCI, we usse the pandas dataframes reader to save the values into Data_train and Data_test.\n",
    "The goal of this is to have two Dataframes holding the values in the file to be used in several classifications.\n",
    "Pandas was used for crosstables and data cleaning through column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('poker-hand-training-true.data', header=None)\n",
    "# print(data_train.shape)\n",
    "data_test = pd.read_csv('poker-hand-testing.data', header=None)\n",
    "# print(data_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now gotten a data_train shape of (25010, 11) where the last column signifies the poker hand class (0-9).\n",
    "Same goes for data_test, where its shape is (1000000, 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns = [\"Suit 1\", \"Card 1\", \"Suit 2\", \"Card 2\", \"Suit 3\", \"Card 3\",\"Suit 4\", \"Card 4\",\"Suit 5\", \"Card 5\",\"Poker Hand\"]\n",
    "# print(data_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Suit 1  Card 1  Suit 2  Card 2  Suit 3  Card 3  Suit 4  Card 4  Suit 5  \\\n",
      "0       1       1       1      13       2       4       2       3       1   \n",
      "1       3      12       3       2       3      11       4       5       2   \n",
      "2       1       9       4       6       1       4       3       2       3   \n",
      "3       1       4       3      13       2      13       2       1       3   \n",
      "4       3      10       2       7       1       2       2      11       4   \n",
      "5       1       3       4       5       3       4       1      12       4   \n",
      "6       2       6       4      11       2       3       4       9       1   \n",
      "7       3       2       4       9       3       7       4       3       4   \n",
      "8       4       4       3      13       1       8       3       9       3   \n",
      "9       1       9       3       8       4       4       1       7       3   \n",
      "\n",
      "   Card 5  Poker Hand  \n",
      "0      12           0  \n",
      "1       5           1  \n",
      "2       9           1  \n",
      "3       6           1  \n",
      "4       9           0  \n",
      "5       6           0  \n",
      "6       7           0  \n",
      "7       5           0  \n",
      "8      10           0  \n",
      "9       5           0  \n"
     ]
    }
   ],
   "source": [
    "data_test.columns = [\"Suit 1\", \"Card 1\", \"Suit 2\", \"Card 2\", \"Suit 3\", \"Card 3\",\"Suit 4\", \"Card 4\",\"Suit 5\",\"Card 5\",\"Poker Hand\"]\n",
    "print(data_test.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pandas column function, we can set the names of the columns to represent Cards/Suits and Poker Hands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Poker Hand type and features: First 10 columns are used in each X_train/X_testwhereas the last column is saved under the y_train/y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.iloc[:,:-1]\n",
    "y_train = data_train[\"Poker Hand\"]\n",
    "\n",
    "X_test = data_test.iloc[:,:-1]\n",
    "y_test = data_test[\"Poker Hand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Training Shape: (25010, 10)\n",
      "X_Testing Shape: (1000000, 10)\n",
      "(25010,)\n",
      "0    9\n",
      "1    9\n",
      "2    9\n",
      "3    9\n",
      "4    9\n",
      "5    8\n",
      "6    8\n",
      "7    8\n",
      "8    8\n",
      "9    8\n",
      "Name: Poker Hand, dtype: int64\n",
      "(1000000,)\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: Poker Hand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X_Training Shape:\",X_train.shape)\n",
    "print(\"X_Testing Shape:\",X_test.shape)\n",
    "print(y_train.head(10))\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_test.head(10))\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We printed the first 10 rows in the head to show that the dataset has, by default, all Poker hands of class 9 in the first 5 rows in the X_Training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first Classifier is the DecisionTreeClassification model. we set a max_depth of 9 and 2 and have differing results. Despite these parameter tunings, we find that the initial percentage is still approxiamtely 50% (Before preprocessing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52719\n",
      "0.501209\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.tree.DecisionTreeClassifier(random_state=0, max_depth = 9, criterion=\"gini\").fit(X_train, y_train)\n",
    "clf2 = sklearn.tree.DecisionTreeClassifier(random_state=0, max_depth = 2, criterion=\"gini\").fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred, normalize=True))\n",
    "                                                                                                \n",
    "y_pred2 = clf2.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred2, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using DecisonTree Classifer and using max_depth of 9 will result in accuracy of 0.52719. To equalize accuracy with that of Logistic Regression, we select max_depth = 2.\n",
    "\n",
    "Our second model will be using LogisticRegression. We begin by setting a max_iter of 100 and use lbfgs. The accuracy prediction also shows an equal percentage as the DecisionTreeClassifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501209"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(random_state=0, solver=\"lbfgs\", max_iter=100, multi_class=\"ovr\").fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to RandomForestClassifier, we set up our model with 3 estimators. The result is slightly better than our previous two (lest it be DecisionTreeCLassifer with max_depth of 9), at 51.41%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.514108"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.ensemble.RandomForestClassifier(criterion='gini', random_state=0, n_estimators=3).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM model is the slowest to train, and unfortunately, the accuracy predition is not better than the other models, resulting in the exact same prediction of 50.12% - we will not continue using this model as the efficacy of training is very slow for no additional benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501209"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "clf = sklearn.svm.SVC(kernel='linear')\n",
    "clf.fit(X_train,y_train) \n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)\n",
    "\n",
    "# from svm 0.501209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to verify our curiosity, we preprocess the data using sklearn's StandardScaler and retrain the svm. The results are still rather disappointing to say the least. Accuracy percentage: 55.63%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the ever popular neural network classifier. Using Sci-kit learn's MLP Neural Network, we attain: before Preprocessing. We decided to use epoch/max_iter set to 1000 whilst also using the adam solver. We have also trained the model with two hidden_layer_size settings: 128,64,10 and 200,150,100. The former returns a 99.12% accuracy whereas the latter returns 98.77%. These results are found using an un-preprecessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLPClassifier : '' 0.987748\n"
     ]
    }
   ],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "   diagonal_sum = confusion_matrix.trace()\n",
    "   sum_of_all_elements = confusion_matrix.sum()\n",
    "   return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "classifier = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(128,64,10), max_iter=1000,activation = 'relu',solver='adam',random_state=1).fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy of MLPClassifier : ''\", accuracy(cm))\n",
    "\n",
    "# Accuracy of MLPClassifier : '' 0.99123 at 200, 150, 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having tested the variety of models on our base dataset, we have an average of 50% accuracy rate. These are poor results if the hope is to have a poker agent that can win big. After all, if the poker agent can only achieve 50 % accuracy, bluffs, all-ins and betting will result in disastrous results in the long run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now preprocess the data to achieve a higher accuracy. In order to do this, we must understand that the dataset is known to be heavily imbalanced. The fact that the columns are set up following the Cards/Suits pattern is cause for accuracy loss. A simple solution would be to rearrange the columns under strictly Cards then strictly Suits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = data_train.copy()\n",
    "cards = X_train_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\"]]\n",
    "cards.values.sort()\n",
    "X_train_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\"]] = cards\n",
    "X_train_processed = X_train_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\", \"Suit 1\", \"Suit 2\", \"Suit 3\", \"Suit 4\", \"Suit 5\", \"Poker Hand\"]]\n",
    "\n",
    "\n",
    "X_test_processed = data_test.copy()\n",
    "cards = X_test_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\"]]\n",
    "cards.values.sort()\n",
    "X_test_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\"]] = cards\n",
    "X_test_processed = X_test_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\", \"Suit 1\", \"Suit 2\", \"Suit 3\", \"Suit 4\", \"Suit 5\", \"Poker Hand\"]]\n",
    "\n",
    "X_train = X_train_processed.loc[:,X_train_processed.columns != \"Poker Hand\"]\n",
    "X_test = X_test_processed.loc[:,X_test_processed.columns != \"Poker Hand\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use a 10 fold Cross-validator on the Classifiers. Starting with the SVM, we get a  accuracy. below shows the svm after preprocessing but without 10-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55635"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "svm = sklearn.svm.SVC(kernel='linear')\n",
    "svm.fit(X_scaled, y_train)\n",
    "t_pred = svm.predict(scaler.transform(X_test))\n",
    "sklearn.metrics.accuracy_score(y_test, t_pred)\n",
    "# from second 0.55635 with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Fold\n",
      "2-Fold\n",
      "3-Fold\n",
      "4-Fold\n",
      "5-Fold\n",
      "6-Fold\n",
      "7-Fold\n",
      "8-Fold\n",
      "9-Fold\n",
      "10-Fold\n",
      "0.5553778488604558\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.svm.SVC(kernel='linear')\n",
    "# cross_validation(alg, X_train, Y_train)\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "    curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    acc.append(curr)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10-CV SVM returns 55.53% - we will no longer train SVM as we were expecting a minimum increase for the long wait time. Better performance can be had much faster with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows the 10-fold CV for DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Fold\n",
      "2-Fold\n",
      "3-Fold\n",
      "4-Fold\n",
      "5-Fold\n",
      "6-Fold\n",
      "7-Fold\n",
      "8-Fold\n",
      "9-Fold\n",
      "10-Fold\n",
      "0.9569372251099562\n"
     ]
    }
   ],
   "source": [
    "# using the same tree as before\n",
    "clf = sklearn.tree.DecisionTreeClassifier(random_state=1, criterion='gini')\n",
    "# cross_validation(alg, X_train, Y_train)\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "    curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    acc.append(curr)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())\n",
    "# return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.960249"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.tree.DecisionTreeClassifier(random_state=1,criterion='gini')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96% is pretty good. We have essentially doubled the correctness of our predictions simply by re-arranging the cards into Cards and Suits. Compared to random state = 0, we get a better result using random state 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>494264</td>\n",
       "      <td>2631</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>498783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1556</td>\n",
       "      <td>408995</td>\n",
       "      <td>11216</td>\n",
       "      <td>1870</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9361</td>\n",
       "      <td>35858</td>\n",
       "      <td>490</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>845</td>\n",
       "      <td>232</td>\n",
       "      <td>17664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "      <td>73</td>\n",
       "      <td>12</td>\n",
       "      <td>3004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5389</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>238</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>501209</td>\n",
       "      <td>422498</td>\n",
       "      <td>47622</td>\n",
       "      <td>21121</td>\n",
       "      <td>3885</td>\n",
       "      <td>1996</td>\n",
       "      <td>1424</td>\n",
       "      <td>230</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True            0       1      2      3     4     5     6    7   8  9      All\n",
       "Predicted                                                                     \n",
       "0          494264    2631      5     19     0  1864     0    0   0  0   498783\n",
       "1            1556  408995  11216   1870   300     1    70    4   0  0   424012\n",
       "2               0    9361  35858    490   153     0   440   23   0  0    46325\n",
       "3               0     845    232  17664     0     0   619  144   0  0    19504\n",
       "4               0     507     73     12  3004     0     0    0  12  0     3608\n",
       "5            5389      24      0      0     0   131     0    0   0  0     5544\n",
       "6               0     125    238   1012     0     0   285   14   0  0     1674\n",
       "7               0       0      0     54     0     0    10   45   0  0      109\n",
       "8               0      10      0      0   292     0     0    0   0  0      302\n",
       "9               0       0      0      0   136     0     0    0   0  3      139\n",
       "All        501209  422498  47622  21121  3885  1996  1424  230  12  3  1000000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_pred, y_test, rownames=['Predicted'], colnames=['True'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing the data shown in the table, we can observe how the True/Predicted values in the upper end have prediction disparity. This means that the flushes and higher reward hands are causing prediction erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = X_test[[\"Suit 1\", \"Suit 2\", \"Suit 3\", \"Suit 4\", \"Suit 5\"]]\n",
    "X_test[\"Unique\"] = tmp.apply(lambda x: len(np.unique(x)) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = X_train[[\"Suit 1\", \"Suit 2\", \"Suit 3\", \"Suit 4\", \"Suit 5\"]]\n",
    "X_train[\"Unique\"] = tmp.apply(lambda x: len(np.unique(x)) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965091"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = sklearn.tree.DecisionTreeClassifier(random_state=0, criterion='gini')\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "accuracy_score(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, we're now at 96%, slightly higher than previously but now the data should be more spread out and the prediciton should be less sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499679</td>\n",
       "      <td>2802</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>503371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530</td>\n",
       "      <td>407933</td>\n",
       "      <td>11807</td>\n",
       "      <td>1759</td>\n",
       "      <td>544</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>423659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10372</td>\n",
       "      <td>35024</td>\n",
       "      <td>618</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>427</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>354</td>\n",
       "      <td>17801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>634</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>607</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>3200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>360</td>\n",
       "      <td>818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>501209</td>\n",
       "      <td>422498</td>\n",
       "      <td>47622</td>\n",
       "      <td>21121</td>\n",
       "      <td>3885</td>\n",
       "      <td>1996</td>\n",
       "      <td>1424</td>\n",
       "      <td>230</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True            0       1      2      3     4     5     6    7   8  9      All\n",
       "Predicted                                                                     \n",
       "0          499679    2802      0     15     0   875     0    0   0  0   503371\n",
       "1            1530  407933  11807   1759   544     7    76    3   0  0   423659\n",
       "2               0   10372  35024    618   141     0   427   28   0  0    46610\n",
       "3               0     640    354  17801     0     0   634  144   0  0    19573\n",
       "4               0     607     77      8  3200     0     0    0   7  0     3899\n",
       "5               0       0      0      0     0  1114     0    0   0  0     1114\n",
       "6               0     144    360    818     0     0   283    6   0  0     1611\n",
       "7               0       0      0    102     0     0     4   49   0  0      155\n",
       "8               0       0      0      0     0     0     0    0   5  0        5\n",
       "9               0       0      0      0     0     0     0    0   0  3        3\n",
       "All        501209  422498  47622  21121  3885  1996  1424  230  12  3  1000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_pred, y_test, rownames=['Predicted'], colnames=['True'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see in this cross tab: flushes have now been resolved but the last two poker hands are still slightly cause for mispredictions. 12-5 and 230-155, still these are very slight but can be cause for accuracy concerns. Straight flushes are bieng underepresented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999836"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"Diff1\"] = X_train[\"Card 5\"] - X_train[\"Card 4\"]\n",
    "X_train[\"Diff2\"] = X_train[\"Card 4\"] - X_train[\"Card 3\"]\n",
    "X_train[\"Diff3\"] = X_train[\"Card 3\"] - X_train[\"Card 2\"]\n",
    "X_train[\"Diff4\"] = X_train[\"Card 2\"] - X_train[\"Card 1\"]\n",
    "\n",
    "X_test[\"Diff1\"] = X_test[\"Card 5\"] - X_test[\"Card 4\"]\n",
    "X_test[\"Diff2\"] = X_test[\"Card 4\"] - X_test[\"Card 3\"]\n",
    "X_test[\"Diff3\"] = X_test[\"Card 3\"] - X_test[\"Card 2\"]\n",
    "X_test[\"Diff4\"] = X_test[\"Card 2\"] - X_test[\"Card 1\"]\n",
    "\n",
    "tree = sklearn.tree.DecisionTreeClassifier(random_state=0, criterion='gini')\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "accuracy_score(y_test, y_pred, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Fold\n",
      "2-Fold\n",
      "3-Fold\n",
      "4-Fold\n",
      "5-Fold\n",
      "6-Fold\n",
      "7-Fold\n",
      "8-Fold\n",
      "9-Fold\n",
      "10-Fold\n",
      "0.9998000799680128\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.tree.DecisionTreeClassifier(random_state=1, criterion='gini')\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "    curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    acc.append(curr)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! Now we find our predictions to be in the upper 99.984% bound of accuracy predicions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>422498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>422498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>501209</td>\n",
       "      <td>422498</td>\n",
       "      <td>47622</td>\n",
       "      <td>21121</td>\n",
       "      <td>3885</td>\n",
       "      <td>1996</td>\n",
       "      <td>1424</td>\n",
       "      <td>230</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True            0       1      2      3     4     5     6    7   8  9      All\n",
       "Predicted                                                                     \n",
       "0          501209       0      0      0     0     0     0    0   0  0   501209\n",
       "1               0  422498      0      0     0     0     0    0   0  0   422498\n",
       "2               0       0  47622      0     0     0     0    0   0  0    47622\n",
       "3               0       0      0  21121     0     0     0    0   0  0    21121\n",
       "4               0       0      0      0  3885     0     0    0   0  0     3885\n",
       "5               0       0      0      0     0  1836     0    0   4  0     1840\n",
       "6               0       0      0      0     0     0  1424    0   0  0     1424\n",
       "7               0       0      0      0     0     0     0  230   0  0      230\n",
       "8               0       0      0      0     0   152     0    0   8  0      160\n",
       "9               0       0      0      0     0     8     0    0   0  3       11\n",
       "All        501209  422498  47622  21121  3885  1996  1424  230  12  3  1000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_pred, y_test, rownames=['Predicted'], colnames=['True'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that the model is bad at predicting flushes and above (The stronger hands). We have concluded that\n",
    "the Decision Tree Classifer is decent at prediciting weaker hands but continuously struugles in predicitng with stronger ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Fold\n",
      "2-Fold\n",
      "3-Fold\n",
      "4-Fold\n",
      "5-Fold\n",
      "6-Fold\n",
      "7-Fold\n",
      "8-Fold\n",
      "9-Fold\n",
      "10-Fold\n",
      "0.9982007197121152\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.ensemble.RandomForestClassifier(criterion='gini', n_estimators=10, random_state=111, n_jobs=4)\n",
    "# cross_validation(alg, X_train, Y_train)\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "    curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    acc.append(curr)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Random Forest Classifier, we get a 99.84% accuracy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Fold\n",
      "2-Fold\n",
      "3-Fold\n",
      "4-Fold\n",
      "5-Fold\n",
      "6-Fold\n",
      "7-Fold\n",
      "8-Fold\n",
      "9-Fold\n",
      "10-Fold\n",
      "0.5527788884446222\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(random_state=0, solver=\"lbfgs\", max_iter=100, multi_class=\"ovr\")\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "    curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    acc.append(curr)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-Fold CV for LogisitcRegression is not that great compared to other models. Sitting at 55.27% accuracy, other models simply outperform this one by 40+ percentage points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network: Here we have excellent results, accuracies close to 100%. By changing the hidden-layers, we approach 99.95% at 150,100,50. This is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLPClassifier : '' 0.99893\n"
     ]
    }
   ],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "   diagonal_sum = confusion_matrix.trace()\n",
    "   sum_of_all_elements = confusion_matrix.sum()\n",
    "   return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "classifier = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(200,150,100), max_iter=1000,activation = 'relu',solver='adam',random_state=1).fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy of MLPClassifier : ''\", accuracy(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of MLPClassifier : '' 99.66% with 128,64,10\n",
    "\n",
    "Accuracy of MLPClassifier : '' 99.95% with 150,100,50\n",
    "\n",
    "Accuracy of MLPClassifier : '' 99.89% with 200,150,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "   diagonal_sum = confusion_matrix.trace()\n",
    "   sum_of_all_elements = confusion_matrix.sum()\n",
    "   return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "clf = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(200,150,100), max_iter=1000,activation = 'relu',solver='adam',random_state=1).fit(X_train, y_train)\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "#     curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    cm = confusion_matrix(fy_test, fy_pred)\n",
    "    acc.append(cm)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU5b3H8c9vZjLZF7IAIQkkICBhU4ggoGKr14WquKCirYjVKlZb7W31qvdqbau1trVVW9S6UNdKrRu4awV3EILsSyCsCQlJIGSdJJOZee4fGWgIWQZMODOT3/v1yisz5zyZ+XFewzdPnvOc54gxBqWUUqHPZnUBSimluocGulJKhQkNdKWUChMa6EopFSY00JVSKkw4rHrj1NRUk52dbdXbK6VUSFqxYsVeY0xae/ssC/Ts7Gzy8/OtenullApJIrKzo3065KKUUmFCA10ppcKEBrpSSoUJDXSllAoTGuhKKRUmNNCVUipMaKArpVSYCLlA37Snhj9+UMD+erfVpSilVFAJuUDfsdfFXxcXUlLdYHUpSikVVEIu0JNjnQBUag9dKaUOoYGulFJhQgNdKaXCRMgFemJ0BDZBT4oqpVQbIRfodpuQFONknwa6UkodIuQCHVqGXfa7NNCVUqq10Az0GCf76jTQlVKqtdAMdO2hK6XUYUIy0PvEOqmsb7a6DKWUCipdBrqIzBORchFZ18F+EZFHRaRQRNaIyLjuL/NQKf4eus9nevqtlFIqZATSQ38WOKeT/ecCQ/1f1wOPf/uyOtcn1onXZ6ht9PT0WymlVMjoMtCNMZ8BlZ00mQ48b1osBZJEJL27CmxPiv/ion31TT35NkopFVK6Yww9Ayhq9bzYv+0wInK9iOSLSH5FRcVRv2Eff6DriVGllPqP7gh0aWdbu4PbxpgnjTF5xpi8tLS0o37Dgz10nbqolFIHdUegFwNZrZ5nAiXd8Lod0h66UkodrjsCfSEwyz/b5WSg2hhT2g2v26HkmANj6BroSil1gKOrBiLyMnA6kCoixcAvgQgAY8wTwLvANKAQcAHX9FSxB0Q77fSJieCbnVU9/VZKKRUyugx0Y8wVXew3wE3dVlGArpmSw58+2szqoirGZiUd67dXSqmgE5JXigL88JQckmOdPPDeRrx6gZFSSoVuoMdFOrj97OEs3VbJ/76xlpY/FJRSqvfqcsglmM2cMJDi/Q38dXEhFbVN/H7GGFLiIq0uSymlLBGyPfQDfn7WMO49P5fPC/dyziOf88WWvVaXpJRSlgj5QBcRZk/JYcFNU0iMjmDWvK95ZXlR1z+olFJhJuQD/YAR6QksvHkKpwxN4/bX1nDPgnUUVbqob9IFvJRSvUPYBDpAjNPB07PymD05mxeX7uTU3y/mxN98pD12pVSvENInRdvjdNi494KRXH5SFquLqnh7TSm3v7aG4qoGfnbmUETaW3pGKaVCX9gF+gEj0hMYkZ7AjPGZ3PXGWh79eAuuJg8/+69hxEaG7T9bKdWLhX2yOew2fnfxGCLsNp7+YjtvrNzNnKlDuGrSIKIi7FaXp5RS3SasxtA7YrMJ9180mtdunMyI9ATuf3cjZzz0KQtW7aax2Wt1eUop1S3Eqiss8/LyTH5+viXv/dXWvfz6rQ1s2lNLrNPOz88azjVTsnV8XSkV9ERkhTEmr719vaKH3tbkIam8/ZNTeO6HE5iQk8yv397ArHnLKCyvs7o0pZQ6ar0y0KFlbH3qsDTmzT6JX08fyapdVZz98Gf89z9XUVrdYHV5Sil1xHptoB8gIsyalM3i205n9uRs3l1XyiWPfaW9daVUyOn1gX5Aalwkd5+Xy2s3Tsbt9XHh3C+Zv2yXruKolAoZGuhtjByQyBs/nsKojATueH0ts+Yto6RKh2CUUsFPA70dWckx/OO6k/nN9JGs2Lmfcx7+jAWrdmtvXSkV1DTQO2CzCVdNyua9W04lJy2OW+av4nuPfsGSrfusLk0ppdqlgd6FQSmxvDZnEn+8dCy1Tc1c8dRSfvfeJqvLUkqpw2igB8BhtzFjfCYf3jqVmSdl8cSnW3UFR6VU0An7tVy6U7TTzn0XjqJ4fwN3vrGWzWW1XDwuk6H94oiw6+9GpZS1NIWOkMNu47EfjOOyvEye/mI70x79nEse/wq3x2d1aUqpXq5XruXSXXbuq+ejDWXc985GZozPZFtFHTPGZ3HlxIFWl6aUClOdreWiQy7fwqCUWK47dTDrdlfz6opiALZW1HPe2HQSoiIsrk4p1dvokEs3+PWFo/jVBSP5x3UTqW5o5u9f7LC6JKVUL6Q99G6QEBXB1ZOzATgrtx+PfVLIyAEJnJnbz9rClFK9ivbQu9kDF49meP94bnhxBe+uLbW6HKVUL6KB3s1S4iJ5+Ucnc0JWErfOX8UXW/ZaXZJSqpcIKNBF5BwRKRCRQhG5o539iSLyloisFpH1InJN95caOmIjHcy7+iQGp8Xy45dWsHNfvdUlKaV6gS4DXUTswFzgXCAXuEJEcts0uwnYYIwZC5wOPCQizm6uNaQkxkTw1Kw8RIQbXliBy+2xuiSlVJgLpIc+ASg0xmwzxriB+cD0Nm0MEC8tN+WMAyqBXp9gWckxPHrFiRSU1XLn62t1tUalVI8KJNAzgNYLlxT7t7X2V2AEUAKsBW4xxhx26aSIXC8i+SKSX1FRcZQlh5apw9L4xVnDWbCqhEc+3mJ1OUqpMBZIoEs729p2Nc8GVgEDgBOAv4pIwmE/ZMyTxpg8Y0xeWlraERcbqm6cOoQZ4zN5+N9bePyTrVaXo5QKU4EEejGQ1ep5Ji098dauAV43LQqB7cDx3VNi6LPZhAcvGcP3xqTz0IcFbCmrtbokpVQYCiTQlwNDRSTHf6JzJrCwTZtdwBkAItIPGA5s685CQ53dJvxm+ihiIx3c8fpaXv+mmCqX2+qylFJhpMtAN8Z4gJuBD4CNwCvGmPUiMkdE5vib/QaYLCJrgY+B/zHG6ATsNpJjndw17XhW7NzPf7+ymqvnLdNVGpVS3UZXW7RAWU0jn2/Zyy/+tZprT8nh7vPazgJVSqn2dbbaol4paoF+CVHMGJ/JFROyeParHZTVNFpdklIqDGigW2jO1CF4fYaXl+2yuhSlVBjQQLfQoJRYpg5L4+Vlu2j26li6Uurb0UC32KxJgyiraeIvetGRUupb0kC32HeP78ul4zN5dFEhb67cbXU5SqkQpoFuMRHh/otGc1J2H+5esI5yPUGqlDpKGuhBwOmw8eAlY2jy+Lj9tTWs211tdUlKqRCkgR4kBqfFcdtZw/mkoILz/vIFLyzZYXVJSqkQo4EeRH502mCW3nkGkwan8IcPCthfr0sDKKUCp4EeZPonRnHvBSOpa/LocrtKqSOigR6EhveP55JxmfxzeRE1jc1Wl6OUChEa6EFq1qRsGpq9vPGNTmVUSgVGAz1Ijc5MZExmIi8u3Ul9U6+/m59SKgAa6EHs2lNy2FJex8Tffsx7a0utLkcpFeQ00IPY9BMyeO3GyQxOi+X2V9dQVOmyuiSlVBDTQA9y4wf1Ye6V4zDAzS+vpNqlJ0mVUu3TQA8BWckxPHTZWDaW1DDjia801JVS7dJADxFnj+zPM7Pz2FJex4tf77S6HKVUENJADyGnDk3jlONSeWHJTl0/XSl1GA30EHPNlGz21DTyrs56UUq1oYEeYr4zvC/H9Y3jgXc36VovSqlDaKCHGJtNePjyE6isd/Pzf63Go0MvSik/DfQQNCojkbvPz2XRpnJuf3UNXp+xuiSlVBBwWF2AOjpXnTyIqno3D320mcKKOn4/YwzH90+wuiyllIW0hx7CfnLGUB6ZeQIlVQ38+MVv8GlPXaleTQM9xE0/IYO7z8tl2956Pt1cYXU5SikLaaCHgWmj0+mXEMm8L7dbXYpSykIa6GEgwm7j6snZfL5lL2+u1PXTleqtNNDDxLWn5DAxJ5nbXl3N8h2VVpejlLJAQIEuIueISIGIFIrIHR20OV1EVonIehH5tHvLVF2JdNh58qo8BiRF87N/rqJOb4qhVK/TZaCLiB2YC5wL5AJXiEhumzZJwGPABcaYkcClPVCr6kJiTAR/umwsJVUN3Pn6Wl3vRaleJpAe+gSg0BizzRjjBuYD09u0uRJ43RizC8AYU969ZapAjR+UzM/PGs5bq0v4/lNf43JrT12p3iKQQM8Ailo9L/Zva20Y0EdEPhGRFSIyq70XEpHrRSRfRPIrKnSKXU+56TvH8dClY1m2o5KXlu6yuhyl1DESSKBLO9vaXsHiAMYD3wPOBu4WkWGH/ZAxTxpj8owxeWlpaUdcrArcJeMzmXJcCk99vo3GZq/V5SiljoFAAr0YyGr1PBMoaafN+8aYemPMXuAzYGz3lKiO1o9PP47y2iZ+994m6vUkqVJhL5BAXw4MFZEcEXECM4GFbdosAE4VEYeIxAATgY3dW6o6UpOHpHDxiRk8+9UOpj36uY6nKxXmugx0Y4wHuBn4gJaQfsUYs15E5ojIHH+bjcD7wBpgGfC0MWZdz5WtAiEi/OnyE5g3O4+d+1w89ZleSapUOBNjrFnQKS8vz+Tn51vy3r3Rj19aweJNFbx7y6nkpMZaXY5S6iiJyApjTF57+/RK0V7iznNH4HTYuHDulyzZus/qcpRSPUADvZfISo5h4c1TSIuP5McvraC8ttHqkpRS3UwDvRcZlBLLEz8YR73by12vr8Oq4TalVM/QQO9ljusbz61nDuXfG8tYX1JjdTlKqW6kgd4LXTlhIE67jVdXFFtdilKqG2mg90JJMU7OzO3LwtUluD26gJdS4UIDvZe6ZFwmlfVuznnkM+5+c52uzKhUGNBA76WmDkvj8rwsMpKieWHpTm795yq8epNppUKaw+oClDUcdhsPzhgDwOOfbOXB9zdx7qj+nDdmgMWVKaWOlvbQFTecNpjBabE8tnirTmVUKoRpoCtsNmHOaUPYUFrDok16bxKlQpUGugLgwhMzyE6J4db5q1i2XW8yrVQo0kBXADgdNv7xo5NJi4/k2meXs7uqweqSlFJHSANdHTQgKZrnfjgBrzHc9q/V+HTWi1IhRQNdHSIrOYb/+14uX23dx5//vdnqcpRSR0CnLarDXDEhi9VFVfxlUSGRDhvXnzYEp0N/9ysV7PR/qTqMiHDfRaOYNro/f/xwMxf89Qu9J6lSIUADXbUrwm5j7pXjeOz749i0p5a/LCq0uiSlVBc00FWHRIRpo9O5dHwmT3++ja0VdVaXpJTqhAa66tL/nHs8NhFeWrrL6lKUUp3QQFddSo2L5LRhaby7tlSnMioVxDTQVUDOH5vOnppGVuzab3UpSqkOaKCrgJwxoh+RDhvPfL6dPdV6g2mlgpEGugpIXKSDKycO5P31e5j6h8UU7Km1uiSlVBsa6Cpgvzx/JB/97DQiHTYeeG+j1eUopdrQQFdHZGi/eG7+7nF8UlDBZ5srrC5HKdWKBro6YrMmZZOTGst/v7JKV2VUKohooKsjFhVh56lZ42lq9nHdc/m43LosgFLBQANdHZXj+sbz6JUnUrCnhp+/okvtKhUMAgp0ETlHRApEpFBE7uik3Uki4hWRGd1XogpW3xnelzvPHcF76/bwyMdbrC5HqV6vy+VzRcQOzAX+CygGlovIQmPMhnbaPQh80BOFquB03ak5FJTV8sjHW0iOdXLVyYOw2cTqspTqlQLpoU8ACo0x24wxbmA+ML2ddj8BXgP0LsO9iIhw/0WjOHVoKr9cuJ7L/raEOl1qVylLBBLoGUBRq+fF/m0HiUgGcBHwRGcvJCLXi0i+iORXVOiUt3AR6bDz/A8n8PsZY1hZVMVPX16JV8fUlTrmAgn09v5+bvu/9WHgf4wx3s5eyBjzpDEmzxiTl5aWFmiNKgSICJflZXHvBSNZtKmcX/xrNR6vz+qylOpVArkFXTGQ1ep5JlDSpk0eMF9EAFKBaSLiMca82S1VqpBx1cmDqGlo5g8fFJAQ5eBX00dZXZJSvUYgPfTlwFARyRERJzATWNi6gTEmxxiTbYzJBl4Ffqxh3nvd9J3jmDE+k1fyi3WOulLHUJeBbozxADfTMntlI/CKMWa9iMwRkTk9XaAKTRePy6Ch2cuiTeUsWLWb8lpdoVGpnibGWHPyKi8vz+Tn51vy3qrneX2Gkx/4GJ/PsK/ezbmj+vP4D8ZbXZZSIU9EVhhj8trbp1eKqh5htwnfG53Ovno3ybFO3l+/h216T1KlepQGuuoxc6YO4dYzh7LgpilE2G08+dk2q0tSKqxpoKse0z8xilvPHEZWcgxXThjIP/OLWLJ1n9VlKRW2NNDVMXHb2cPJSYnlpn98w8WPfckry4u6/iGl1BHRQFfHRGykg79ceSKDU2OpcjVzx+trWLpNe+tKdScNdHXMjByQyKs3TmbBzVPITonllvkraWzu9OJipdQR0EBXx1x8VAT3XTSKspomXl1RbHU5SoUNDXRliUmDUxibmchTn2/ThbyU6iYa6MoSIsKcqUPYuc/FhPv/zbNfbre6JKVCnga6ssw5o/rz58vHMiglhgfe20RZTSPzvthOWY0uE6DU0QhktUWleoSIcNGJmYzNTOLMP33KRXO/pKS6kZ376nWVRqWOgvbQleUGp8XxvTEDKKluJMZp5+NN5Vi1xpBSoUx76Coo3HNeLpOHpODxGe5+cx1byutIiongJ/9YyaV5WcwYn2l1iUoFPQ10FRTS4iO5YsJA9lQ3cveb65j3xXZW7NzPlvI6qhuaNdCVCoAOuaig0j8xipEDEpi/vIjS6kbOG5POpj217Nhbb3VpSgU97aGroHPfhaPYWFrLeWPTqWlo5u01pby/fg9zpg6xujSlgpr20FXQOXFgH66cOJCEqAgy+8QwOiORt9eU6IlSpbqgga6C3pUTB7Judw1PfKrrqSvVGQ10FfRmnpTFeWPS+cMHm1i8qdzqcpQKWhroKuiJCA9eMobcAQnc+NIKvm617G5ZTSO7qxosrE6p4KGBrkJCbKSDZ6+ZwICkaH7wzNe8sGQHbo+PK55cyg//vtzq8pQKChroKmSkxkXy+o2TOXVoGncvWM9Vz3zNtr31FJTVUlTpsro8pSynga5CSlKMk6dm5TFtdH++3l7JiPQEABbp2LpSGugq9Nhtwp8vP4G7ph3PM1fnkZMaq4GuFBroKkRFOuxcf9oQBiRF853hfVmybR81jc1Wl6WUpTTQVci78MQBeH2GW+evYktZLQtW7ebxT7ZS3+SxujSljim99F+FvDGZSdx7wUjufnPdIUMvVS43d04bYWFlSh1bGugqLFx18iD6xkdS1+ghd0ACz3yxnXlfbmfmhIHkpMZaXZ5Sx4QOuaiwcfbI/lwyPpMR6Qncfs5wIh12Zv99GUtbXYikVDgLKNBF5BwRKRCRQhG5o5393xeRNf6vr0RkbPeXqlTg+sZH8fdrTsIYmPnkUv7vzbW43DqmrsJbl4EuInZgLnAukAtcISK5bZptB6YaY8YAvwGe7O5ClTpSJ2Un8/6tp3LtKTm89PUufvR8Po3NXowxvLB0J9t1jXXVhjEmpFf1DKSHPgEoNMZsM8a4gfnA9NYNjDFfGWP2+58uBfT2MiooxDgd3H1eLn+cMZYvC/fxk5dX8s7aUu5+cx1//miz1eWpIPO79zfx/ae/trqMoxbISdEMoKjV82JgYiftrwXea2+HiFwPXA8wcODAAEtU6tu7ZHwmtY3N3PvWhoMrNn60oQyX20OMU+cGqBbbKupD+i+3QHro0s62dv8mEZHv0BLo/9PefmPMk8aYPGNMXlpaWuBVKtUNZk/JYfbkbAxw29nDaWj28u+NLeFeXttIY7PX2gKV5VxuDy536H4OAumaFANZrZ5nAiVtG4nIGOBp4FxjjE4rUEHpl+fncvN3jyM5xskLS3by6MdbeHdNKR9u2MN3hvfl6avzEGmvD6N6g/omLw0hHOiB9NCXA0NFJEdEnMBMYGHrBiIyEHgduMoYowOTKmiJCKlxkdhswpypg6ltbGbFrv1MHpLKx5vK+XhjOT5f6J4UU9+Oy+3B7fXh8fqsLuWodNlDN8Z4RORm4APADswzxqwXkTn+/U8A9wApwGP+3o3HGJPXc2Ur9e3NnpLD7Ck5ADR7fUx75HOufyEfgMe+P45zRqVbWZ6yQH1TS+/c1ewlwR56l+kEdDbIGPMu8G6bbU+0enwdcF33lqbUsRNht/HwzBN4bcVuPtlczm/e3sjpw/sSFWG3urSw9dCHBRSW1/H4D8ZbXcpB9f5rFRrcXhKiIiyu5siF3q8gpXrIyAGJ3HN+LvdfOJrdVQ3c984GPVHag77ZtZ81xdVWl3EIl7+HHqrj6BroSrUxaUgKV04cyItLd3HGQ59SXttodUlHpbHZyze79nfd0CL76tzUBtGSx26PD7d/7DxUZ7pooCvVjt9eNJqXrptIRW0Tv1q4ISSvIHx1RTEzHv+K/fVuq0tp1756N3VNnqA5rq175Q3NoblMhAa6Uh2Yclwqt5w5lHfWljL63g855cHFvPT1zqAJoK6U1TTiM7C3rsnqUg7j8xkq6934DDQEybBWfau1fkK1h66XyCnVietPG0xpdQOCsKG0hv99Yx0RNhuXnZTV9Q9brMrVMpyx3xU8wxoH1DQ24/VPD61rDI6rdV0a6EqFtwi7jfsuHA209Cov/dsSHnx/E30TInE6bEwekmpxhR3b73If8j2Y7K37T021TR76WljLAQemLIKeFFUq7Nlswq8uGEmly83svy/nqmeWsXNf8K77caCHXhWEgb6v1TBQXWNwjFe3HnIJlmGgI6WBrtQRGJWRyNOz8nj48hNw2IS/Liq0uqQOHeiZV9YH35BLZasTtXVBcu9XV6seug65KNVLnDGiHwCri6t4fslOZk/JJtJhZ8XOSi7LywqatWCCuYe+t1Wg1wZjDz1Eb4aiga7UUbrx9CG8s6aUy/+2FK/P0NDsJSnGydkj+1tdGvCfIA/GMfRDhlyCpIdeHwY9dB1yUeoo9Y2P4s2bpjCkbxzjB/VhcGosf/igAJfbwycF5cxdXIjbY80iT26Pj3p/KAXjLJfKejc2/x8ydUFycdGBWS42Cd1A1x66Ut/CgKRoFtw0BYD315Uy58VvyL3ng4P7k2OdXDHh2N/MparhP73yYLywaF+dm4w+0RRVNgRdDz051qmzXJTq7c4e2Z9fnp/LL84axhM/GM+ojASe+nwbPp+hvLaRB97dSGl1w1G//k9eXslPX14ZUNsD4+d2mwTnkEt9E+kJ0TgdNmqDJNBdbg+RDhtxkY6QneWiPXSluomIcI1/OV4At9fHT19eyW/f3ciiTeVs21vPok3l/GvOJJJinIf8rM9n+PXbGzhnVH9OHpxy2Gs3e318vLGMJo+Pe87PJTUustNaDvTKs/pEHwz3I2WMYfrcL/n+xIFcflL3/pWxr87NkLQ44iMdPT5tsdnrw+M1RDs7Xzmz3u0hNtJBtNMRskMu2kNXqodMG9WfiTnJPP3Fdsprm/jfaSPYuc/FRY99xSv5RcxdXMhnmyvweH28uWo3z361g1+9taHdpQU2ltbgcnvx+gxvrz7shmGHqWpoCfGc1FiqGpqP6qYdFbVNrCmuZpH/HqzdaV+9m5Q4J3FRDup7uIf+hw8KuOTxr7ps52ryEuO0E+O0h+xaLtpDV6qHOOw2/nnDJPbXu3HYhfioCEZlJHL7a6u5/dU1B9sNSomhsdlLXKSDjaU1LNpUzqiMRPolRB1ss3xHy6qJGUnRvLGq5OCNOTpyYIZLdmosiwsqqG30kBhzZOt7b61ouWhqQ2lNp+2MMZRWNzIgKTqg1/X6DPtdblLiIomLdPT4GPqa4ioKymrxeH04OrlpRb3bQ1ykgxinPWjG9Y+U9tCV6mF9Yp3E+2+WMGlICh/eOpW3bj6FVff8F3OvHEeE3UZZTROP/2Ac6YlRXPtcPhN/+zGz/76MwvI6AFbsrCSzTzRXTx7E6qIqtpTVdvqeB2a2DE6N9T8/8nH07XtbAr2osoGaTmaivLFyN6f9fjElVYGdHyiqdGEMZCZFExvp6PF56EWVDXh9hj01nS+D7HK39NCjI+x6UlQpFZhop53RmYkkxTj53ph03rvlVBb/4nROHZrG/ReN4ooJWfzku8exYsd+znn4M+5+cx1fb6skb1AfLhmXidNu4/klOw++3v56N3e9sZarnvmaX/uHbKpczTjtNjL6tPSajybQt1XUHXy8qbTjXyAfbSjD4zOs3R3YzSoK/L+Mhvbzj6H3YG+42es7eCK6eH/nv3Dqmw6ModtDdgxdh1yUsliE3UaOvyf93eP78d3jW65EvXpyNg99WMD85bto9homDk4hJS6S88am89o3xdx2znB27K3nuufy2e9yk5May+db9nLu6P5UudwkxUQcPPl6NCdGt+2tJzUukr11TWwoqWZCTvJhbTxeH18W7gVaxvkDuahqy8FAjycuykFdRc8FeklVAwdOH+zuItBdbi9p8ZH+MXQNdKVUN0qNi+SBi8dw17QRrC2u5iR/oM6enM3r3+zm6nnLKCyrIzEmgjdvmkJOaiyTHljE37/cjtdn6BPjJNkf6JVHMRd9W0UdE3OSWbptX7vj6Mu2V9Lk8VLjHzLZ2MVY+wGby+rISIomLtLRMoZ+FEMu1Q3NVNa7D/4i7MiuStfBx7u7GBKqa/IQ63QQHeHQIRelVM+Ij4pg8nGpRPhP6I3JTGpZ9bHeTd+ESF65YRIjByQS43Qwc0IW76/bw6qiKhJjIkiJawn09m5FZ4xhW0Vdu7Nq3B4fRfsbGJwWS+6ABNbtPjSsP91cwWV/W8K1z+YjApOHpLBpT+fj+gtW7ea9taVsLqtlWL84AOKiHEc1D/2372zkwrlf4vF2fiVuUWVLiEfYJaAeekxkyywXlzt47qR0JLSHrlQIunpyNrMmDcKYlmV9D5g9OZu3V5fS5PExdVga8VERzJo0iOeX7GREegIDkqJYsKqEQckx7K1384+vd3H1pEHce8FIRARjDCLCrsp6vD7D4LRY4iIdPPDeJr7aupfJQ1IxxvDQhwX0jY+ksdnL6H6JTB6Swh8/3ExdU8tMkbZqG5u58/W12Bg19vUAAAicSURBVG1CU3NLbQDxkQ7cHh9NHi+Rjs7niR9gjOHzLRVUNzSzuria8YP6dNh2V6WLCLuQm55AcZWrw3bgH0N3toyh+ww0eXxERQRWU7DQQFcqRIkIbRd2TE+M5ss7vnvItrumjWDlrir+7811ACREOQ4Ok4wbmMRzS3by6eYK6po87Hc1k50Sg83/wjmpcZw7Kp0Xlu7kVws38KvpI1m0qZw1xdX8fsYYzji+5dYUK3dVAVCwp4bxgw4fa39j5e5DTjQO7RcPcDD865sCD/RdlS5KqltmrHxZuLfTQC+qdJGRFE1mcgzrOzlpW9/kocnjI9Y/bRFabnKhga6UCipREXb+NWcSa4qrcbk9nDw4hV2VLsprmphyXAp/WVTI+pJqUuIiiY9yUFhWh9vrY9rodEZnJGK3Cfecl8sNL65g5pNLATgrtx8Xn5hxcF738ektAX3/OxsZlBKLx2eIi3QwJjORE7KSeH7JTsZkJhLjtLN0W2WrIZeW6Zx1jR6SY53tVH+4r7buAyA1zskXhXv56RlDO2xbtN9FVnIMmUnRfLS+DJ/PHPIXzQEL/RdrTR6ScnCqqKvZS8e/KoKTBrpSvUBUhP2QWSrD+sUzzN9L7iwQDzhrZH8W/fx0iipd5KTGkpUcc8j+jKRozhuTzobSGip2VuKw2ahyuXl52a6DbR6ZeQIDk2OYu3grw/sf2kO/4/U1jB/Uh5EDEhiVkYjTYcPjNTR7fTR7DQnRLScqd1c1sHhTOWnxkVw8LoN5X2w/eBVty1osduYv30Vto4cTByaxtbyOC0/MIKNPNG6vj4q6poMXbHm8Ph7+9xYAFheUM7xfPOMH9Tl48jQUT4xqoCulApKTGtvhrBIR4a9XjjtkmzGG9SU1bK2oY1i/eEakJwDw9NV5B9ucPDiZS8ZlsnZ3FY99svXgjaO7csHYAUwdmsbfPt3GuY98fsi+GKedpOgIPtpQRv+EKM4a2R+vr+Xk6W2vrqHB7aGkqpGkmAjWl/znZO+vp7ecRzhww+pPCspx2IQ+sU5inPaDJ6Vba3B7Ka1uYE9NI067jdS4SCIcNhZtKuet1SUU7KlleP94kqIjsNuE+CgHl5+U1e6wVHcQq87k5uXlmfz8fEveWykVfBqbvWworWFDSQ0GcNqFCLsNu02obmgmwm6jf2IUG0trOCu3P0PSYlm0qZx6t5f4KAcxEXb2u9xMyEmhT0xEy3oxsU5EhPomD/e9s4EvCveSGB1BVp8YCspquWZKDpEOG2+tLmHu98eREBVBUaWLS59YctiVpRF2ITrCTozTQVSEjf2uZqobOp7ff1zfOMYNTKKwvO7gOjx7ahqpbfRww2mDuXPaiKM6TiKywhiT1+4+DXSllDqUz2dYVVzF9op69rvcNLi9uJq9Ld/dHhqaffSJiaB/YhTpiVH0i4+i2WfYW9tEbWMzJw9JYXi/+MNuR+hye5i/rIixWYlH3UvvLNB1yEUppdqw2YRxA/swbmD3nhaNcTr44SmdL6z2bQR0YZGInCMiBSJSKCJ3tLNfRORR//41IjKuvddRSinVc7oMdBGxA3OBc4Fc4AoRyW3T7FxgqP/reuDxbq5TKaVUFwLpoU8ACo0x24wxbmA+ML1Nm+nA86bFUiBJRNK7uVallFKdCCTQM4CiVs+L/duOtA0icr2I5ItIfkVFxZHWqpRSqhOBBPrhl1VB26kxgbTBGPOkMSbPGJOXlpYWSH1KKaUCFEigFwNZrZ5nAm1vahhIG6WUUj0okEBfDgwVkRwRcQIzgYVt2iwEZvlnu5wMVBtjSru5VqWUUp3och66McYjIjcDHwB2YJ4xZr2IzPHvfwJ4F5gGFAIu4JqeK1kppVR7LLtSVEQqgJ1dNmxfKrC3G8sJB3pMDqfH5FB6PA4XisdkkDGm3ZOQlgX6tyEi+R1d+tpb6TE5nB6TQ+nxOFy4HRO9BZ1SSoUJDXSllAoToRroT1pdQBDSY3I4PSaH0uNxuLA6JiE5hq6UUupwodpDV0op1YYGulJKhYmQC/Su1mbvDURkh4isFZFVIpLv35YsIh+JyBb/91C7YfkREZF5IlIuIutabevwGIjInf7PTIGInG1N1T2rg2Nyr4js9n9WVonItFb7wvqYiEiWiCwWkY0isl5EbvFvD9/PiTEmZL5ouVJ1KzAYcAKrgVyr67LgOOwAUtts+z1wh//xHcCDVtfZw8fgNGAcsK6rY0DLOv6rgUggx/8Zslv9bzhGx+Re4BfttA37YwKkA+P8j+OBzf5/d9h+TkKthx7I2uy91XTgOf/j54ALLaylxxljPgMq22zu6BhMB+YbY5qMMdtpWaJiwjEp9Bjq4Jh0JOyPiTGm1Bjzjf9xLbCRlmW9w/ZzEmqBHtC6672AAT4UkRUicr1/Wz/jXxDN/72vZdVZp6Nj0Ns/Nzf7bw05r9XwQq86JiKSDZwIfE0Yf05CLdADWne9F5hijBlHy63/bhKR06wuKMj15s/N48AQ4ASgFHjIv73XHBMRiQNeA241xtR01rSdbSF1TEIt0HXddcAYU+L/Xg68QcufhWUHbvvn/15uXYWW6egY9NrPjTGmzBjjNcb4gKf4zxBCrzgmIhJBS5i/ZIx53b85bD8noRbogazNHtZEJFZE4g88Bs4C1tFyHK72N7saWGBNhZbq6BgsBGaKSKSI5NByM/NlFtR3zLW5t+9FtHxWoBccExER4BlgozHmT612he3npMv10IOJ6WBtdovLOtb6AW+0fFZxAP8wxrwvIsuBV0TkWmAXcKmFNfY4EXkZOB1IFZFi4JfA72jnGJiW9ftfATYAHuAmY4zXksJ7UAfH5HQROYGWoYMdwA3Qa47JFOAqYK2IrPJvu4sw/pzopf9KKRUmQm3IRSmlVAc00JVSKkxooCulVJjQQFdKqTChga6UUmFCA10ppcKEBrpSSoWJ/wctEWM1CL5+ggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = classifier.loss_curve_\n",
    "plt.plot(loss_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLPClassifier : '' 0.989447\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = sklearn.neural_network.MLPClassifier(learning_rate = 'constant',alpha=0.001,hidden_layer_sizes=(128,64,10), max_iter=1000,activation = 'relu',solver='adam',random_state=1).fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy of MLPClassifier : ''\", accuracy(cm))\n",
    "\n",
    "loss_values = classifier.loss_curve_\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self, n_features):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 5)\n",
    "    self.fc2 = nn.Linear(5, 3)\n",
    "    self.fc3 = nn.Linear(3, 1)\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    return torch.sigmoid(self.fc3(x))\n",
    "net = Net(X_train.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
