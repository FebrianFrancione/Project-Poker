{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Poker Hands UCI Classifications\n",
    "The Poker Hands dataset is taken from here: https://archive.ics.uci.edu/ml/datasets/Poker+Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.tree \n",
    "import sklearn.ensemble\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Poker Hands Dataset from UCI, we usse the pandas dataframes reader to save the values into Data_train and Data_test.\n",
    "The goal of this is to have two Dataframes holding the values in the file to be used in several classifications.\n",
    "Pandas was used for crosstables and data cleaning through column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('poker-hand-training-true.data', header=None)\n",
    "# print(data_train.shape)\n",
    "data_test = pd.read_csv('poker-hand-testing.data', header=None)\n",
    "# print(data_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now gotten a data_train shape of (25010, 11) where the last column signifies the poker hand class (0-9).\n",
    "Same goes for data_test, where its shape is (1000000, 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns = [\"Suit 1\", \"Card 1\", \"Suit 2\", \"Card 2\", \"Suit 3\", \"Card 3\",\"Suit 4\", \"Card 4\",\"Suit 5\", \"Card 5\",\"Poker Hand\"]\n",
    "# print(data_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Suit 1  Card 1  Suit 2  Card 2  Suit 3  Card 3  Suit 4  Card 4  Suit 5  \\\n",
      "0       1       1       1      13       2       4       2       3       1   \n",
      "1       3      12       3       2       3      11       4       5       2   \n",
      "2       1       9       4       6       1       4       3       2       3   \n",
      "3       1       4       3      13       2      13       2       1       3   \n",
      "4       3      10       2       7       1       2       2      11       4   \n",
      "5       1       3       4       5       3       4       1      12       4   \n",
      "6       2       6       4      11       2       3       4       9       1   \n",
      "7       3       2       4       9       3       7       4       3       4   \n",
      "8       4       4       3      13       1       8       3       9       3   \n",
      "9       1       9       3       8       4       4       1       7       3   \n",
      "\n",
      "   Card 5  Poker Hand  \n",
      "0      12           0  \n",
      "1       5           1  \n",
      "2       9           1  \n",
      "3       6           1  \n",
      "4       9           0  \n",
      "5       6           0  \n",
      "6       7           0  \n",
      "7       5           0  \n",
      "8      10           0  \n",
      "9       5           0  \n"
     ]
    }
   ],
   "source": [
    "data_test.columns = [\"Suit 1\", \"Card 1\", \"Suit 2\", \"Card 2\", \"Suit 3\", \"Card 3\",\"Suit 4\", \"Card 4\",\"Suit 5\",\"Card 5\",\"Poker Hand\"]\n",
    "print(data_test.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pandas column function, we can set the names of the columns to represent Cards/Suits and Poker Hands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Poker Hand type and features: First 10 columns are used in each X_train/X_testwhereas the last column is saved under the y_train/y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.iloc[:,:-1]\n",
    "y_train = data_train[\"Poker Hand\"]\n",
    "\n",
    "X_test = data_test.iloc[:,:-1]\n",
    "y_test = data_test[\"Poker Hand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Training Shape: (25010, 10)\n",
      "X_Testing Shape: (1000000, 10)\n",
      "(25010,)\n",
      "0    9\n",
      "1    9\n",
      "2    9\n",
      "3    9\n",
      "4    9\n",
      "5    8\n",
      "6    8\n",
      "7    8\n",
      "8    8\n",
      "9    8\n",
      "Name: Poker Hand, dtype: int64\n",
      "(1000000,)\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: Poker Hand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X_Training Shape:\",X_train.shape)\n",
    "print(\"X_Testing Shape:\",X_test.shape)\n",
    "print(y_train.head(10))\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_test.head(10))\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We printed the first 10 rows in the head to show that the dataset has, by default, all Poker hands of class 9 in the first 5 rows in the X_Training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first Classifier is the DecisionTreeClassification model. we set a max_depth of 9 and 2 and have differing results. Despite these parameter tunings, we find that the initial percentage is still approxiamtely 50% (Before preprocessing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52719\n",
      "0.501209\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.tree.DecisionTreeClassifier(random_state=0, max_depth = 9, criterion=\"gini\").fit(X_train, y_train)\n",
    "clf2 = sklearn.tree.DecisionTreeClassifier(random_state=0, max_depth = 2, criterion=\"gini\").fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred, normalize=True))\n",
    "                                                                                                \n",
    "y_pred2 = clf2.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred2, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using DecisonTree Classifer and using max_depth of 9 will result in accuracy of 0.52719. To equalize accuracy with that of Logistic Regression, we select max_depth = 2.\n",
    "\n",
    "Our second model will be using LogisticRegression. We begin by setting a max_iter of 100 and use lbfgs. The accuracy prediction also shows an equal percentage as the DecisionTreeClassifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501209"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(random_state=0, solver=\"lbfgs\", max_iter=100, multi_class=\"ovr\").fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to RandomForestClassifier, we set up our model with 3 estimators. The result is slightly better than our previous two (lest it be DecisionTreeCLassifer with max_depth of 9), at 51.41%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.514108"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.ensemble.RandomForestClassifier(criterion='gini', random_state=0, n_estimators=3).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM model is the slowest to train, and unfortunately, the accuracy predition is not better than the other models, resulting in the exact same prediction of 50.12% - we will not continue using this model as the efficacy of training is very slow for no additional benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501209"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "clf = sklearn.svm.SVC(kernel='linear')\n",
    "clf.fit(X_train,y_train) \n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)\n",
    "\n",
    "# from svm 0.501209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to verify our curiosity, we preprocess the data using sklearn's StandardScaler and retrain the svm. The results are still rather disappointing to say the least. Accuracy percentage: 55.63%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the ever popular neural network classifier. Using Sci-kit learn's MLP Neural Network, we attain: before Preprocessing. We decided to use epoch/max_iter set to 1000 whilst also using the adam solver. We have also trained the model with two hidden_layer_size settings: 128,64,10 and 200,150,100. The former returns a 99.12% accuracy whereas the latter returns 98.77%. These results are found using an un-preprecessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLPClassifier : '' 0.987748\n"
     ]
    }
   ],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "   diagonal_sum = confusion_matrix.trace()\n",
    "   sum_of_all_elements = confusion_matrix.sum()\n",
    "   return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "classifier = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(128,64,10), max_iter=1000,activation = 'relu',solver='adam',random_state=1).fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy of MLPClassifier : ''\", accuracy(cm))\n",
    "\n",
    "# Accuracy of MLPClassifier : '' 0.99123 at 200, 150, 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having tested the variety of models on our base dataset, we have an average of 50% accuracy rate. These are poor results if the hope is to have a poker agent that can win big. After all, if the poker agent can only achieve 50 % accuracy, bluffs, all-ins and betting will result in disastrous results in the long run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now preprocess the data to achieve a higher accuracy. In order to do this, we must understand that the dataset is known to be heavily imbalanced. The fact that the columns are set up following the Cards/Suits pattern is cause for accuracy loss. A simple solution would be to rearrange the columns under strictly Cards then strictly Suits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = data_train.copy()\n",
    "cards = X_train_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\"]]\n",
    "cards.values.sort()\n",
    "X_train_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\"]] = cards\n",
    "X_train_processed = X_train_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\", \"Suit 1\", \"Suit 2\", \"Suit 3\", \"Suit 4\", \"Suit 5\", \"Poker Hand\"]]\n",
    "\n",
    "\n",
    "X_test_processed = data_test.copy()\n",
    "cards = X_test_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\"]]\n",
    "cards.values.sort()\n",
    "X_test_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\"]] = cards\n",
    "X_test_processed = X_test_processed[[\"Card 1\", \"Card 2\", \"Card 3\", \"Card 4\", \"Card 5\", \"Suit 1\", \"Suit 2\", \"Suit 3\", \"Suit 4\", \"Suit 5\", \"Poker Hand\"]]\n",
    "\n",
    "X_train = X_train_processed.loc[:,X_train_processed.columns != \"Poker Hand\"]\n",
    "X_test = X_test_processed.loc[:,X_test_processed.columns != \"Poker Hand\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use a 10 fold Cross-validator on the Classifiers. Starting with the SVM, we get a  accuracy. below shows the svm after preprocessing but without 10-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55635"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "svm = sklearn.svm.SVC(kernel='linear')\n",
    "svm.fit(X_scaled, y_train)\n",
    "t_pred = svm.predict(scaler.transform(X_test))\n",
    "sklearn.metrics.accuracy_score(y_test, t_pred)\n",
    "# from second 0.55635 with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Fold\n",
      "2-Fold\n",
      "3-Fold\n",
      "4-Fold\n",
      "5-Fold\n",
      "6-Fold\n",
      "7-Fold\n",
      "8-Fold\n",
      "9-Fold\n",
      "10-Fold\n",
      "0.5553778488604558\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.svm.SVC(kernel='linear')\n",
    "# cross_validation(alg, X_train, Y_train)\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "    curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    acc.append(curr)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10-CV SVM returns 55.53% - we will no longer train SVM as we were expecting a minimum increase for the long wait time. Better performance can be had much faster with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows the 10-fold CV for DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Fold\n",
      "2-Fold\n",
      "3-Fold\n",
      "4-Fold\n",
      "5-Fold\n",
      "6-Fold\n",
      "7-Fold\n",
      "8-Fold\n",
      "9-Fold\n",
      "10-Fold\n",
      "0.9569372251099562\n"
     ]
    }
   ],
   "source": [
    "# using the same tree as before\n",
    "clf = sklearn.tree.DecisionTreeClassifier(random_state=1, criterion='gini')\n",
    "# cross_validation(alg, X_train, Y_train)\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "    curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    acc.append(curr)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())\n",
    "# return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.960249"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.tree.DecisionTreeClassifier(random_state=1,criterion='gini')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96% is pretty good. We have essentially doubled the correctness of our predictions simply by re-arranging the cards into Cards and Suits. Compared to random state = 0, we get a better result using random state 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>494264</td>\n",
       "      <td>2631</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>498783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1556</td>\n",
       "      <td>408995</td>\n",
       "      <td>11216</td>\n",
       "      <td>1870</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9361</td>\n",
       "      <td>35858</td>\n",
       "      <td>490</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>845</td>\n",
       "      <td>232</td>\n",
       "      <td>17664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "      <td>73</td>\n",
       "      <td>12</td>\n",
       "      <td>3004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5389</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>238</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>501209</td>\n",
       "      <td>422498</td>\n",
       "      <td>47622</td>\n",
       "      <td>21121</td>\n",
       "      <td>3885</td>\n",
       "      <td>1996</td>\n",
       "      <td>1424</td>\n",
       "      <td>230</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True            0       1      2      3     4     5     6    7   8  9      All\n",
       "Predicted                                                                     \n",
       "0          494264    2631      5     19     0  1864     0    0   0  0   498783\n",
       "1            1556  408995  11216   1870   300     1    70    4   0  0   424012\n",
       "2               0    9361  35858    490   153     0   440   23   0  0    46325\n",
       "3               0     845    232  17664     0     0   619  144   0  0    19504\n",
       "4               0     507     73     12  3004     0     0    0  12  0     3608\n",
       "5            5389      24      0      0     0   131     0    0   0  0     5544\n",
       "6               0     125    238   1012     0     0   285   14   0  0     1674\n",
       "7               0       0      0     54     0     0    10   45   0  0      109\n",
       "8               0      10      0      0   292     0     0    0   0  0      302\n",
       "9               0       0      0      0   136     0     0    0   0  3      139\n",
       "All        501209  422498  47622  21121  3885  1996  1424  230  12  3  1000000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_pred, y_test, rownames=['Predicted'], colnames=['True'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing the data shown in the table, we can observe how the True/Predicted values in the upper end have prediction disparity. This means that the flushes and higher reward hands are causing prediction erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = X_test[[\"Suit 1\", \"Suit 2\", \"Suit 3\", \"Suit 4\", \"Suit 5\"]]\n",
    "X_test[\"Unique\"] = tmp.apply(lambda x: len(np.unique(x)) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = X_train[[\"Suit 1\", \"Suit 2\", \"Suit 3\", \"Suit 4\", \"Suit 5\"]]\n",
    "X_train[\"Unique\"] = tmp.apply(lambda x: len(np.unique(x)) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965091"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = sklearn.tree.DecisionTreeClassifier(random_state=0, criterion='gini')\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "accuracy_score(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, we're now at 96%, slightly higher than previously but now the data should be more spread out and the prediciton should be less sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499679</td>\n",
       "      <td>2802</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>503371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530</td>\n",
       "      <td>407933</td>\n",
       "      <td>11807</td>\n",
       "      <td>1759</td>\n",
       "      <td>544</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>423659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10372</td>\n",
       "      <td>35024</td>\n",
       "      <td>618</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>427</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>354</td>\n",
       "      <td>17801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>634</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>607</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>3200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>360</td>\n",
       "      <td>818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>501209</td>\n",
       "      <td>422498</td>\n",
       "      <td>47622</td>\n",
       "      <td>21121</td>\n",
       "      <td>3885</td>\n",
       "      <td>1996</td>\n",
       "      <td>1424</td>\n",
       "      <td>230</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True            0       1      2      3     4     5     6    7   8  9      All\n",
       "Predicted                                                                     \n",
       "0          499679    2802      0     15     0   875     0    0   0  0   503371\n",
       "1            1530  407933  11807   1759   544     7    76    3   0  0   423659\n",
       "2               0   10372  35024    618   141     0   427   28   0  0    46610\n",
       "3               0     640    354  17801     0     0   634  144   0  0    19573\n",
       "4               0     607     77      8  3200     0     0    0   7  0     3899\n",
       "5               0       0      0      0     0  1114     0    0   0  0     1114\n",
       "6               0     144    360    818     0     0   283    6   0  0     1611\n",
       "7               0       0      0    102     0     0     4   49   0  0      155\n",
       "8               0       0      0      0     0     0     0    0   5  0        5\n",
       "9               0       0      0      0     0     0     0    0   0  3        3\n",
       "All        501209  422498  47622  21121  3885  1996  1424  230  12  3  1000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_pred, y_test, rownames=['Predicted'], colnames=['True'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see in this cross tab: flushes have now been resolved but the last two poker hands are still slightly cause for mispredictions. 12-5 and 230-155, still these are very slight but can be cause for accuracy concerns. Straight flushes are bieng underepresented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999836"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"Diff1\"] = X_train[\"Card 5\"] - X_train[\"Card 4\"]\n",
    "X_train[\"Diff2\"] = X_train[\"Card 4\"] - X_train[\"Card 3\"]\n",
    "X_train[\"Diff3\"] = X_train[\"Card 3\"] - X_train[\"Card 2\"]\n",
    "X_train[\"Diff4\"] = X_train[\"Card 2\"] - X_train[\"Card 1\"]\n",
    "\n",
    "X_test[\"Diff1\"] = X_test[\"Card 5\"] - X_test[\"Card 4\"]\n",
    "X_test[\"Diff2\"] = X_test[\"Card 4\"] - X_test[\"Card 3\"]\n",
    "X_test[\"Diff3\"] = X_test[\"Card 3\"] - X_test[\"Card 2\"]\n",
    "X_test[\"Diff4\"] = X_test[\"Card 2\"] - X_test[\"Card 1\"]\n",
    "\n",
    "tree = sklearn.tree.DecisionTreeClassifier(random_state=0, criterion='gini')\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "accuracy_score(y_test, y_pred, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Fold\n",
      "2-Fold\n",
      "3-Fold\n",
      "4-Fold\n",
      "5-Fold\n",
      "6-Fold\n",
      "7-Fold\n",
      "8-Fold\n",
      "9-Fold\n",
      "10-Fold\n",
      "0.9998000799680128\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.tree.DecisionTreeClassifier(random_state=1, criterion='gini')\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "    curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    acc.append(curr)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! Now we find our predictions to be in the upper 99.984% bound of accuracy predicions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>422498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>422498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>501209</td>\n",
       "      <td>422498</td>\n",
       "      <td>47622</td>\n",
       "      <td>21121</td>\n",
       "      <td>3885</td>\n",
       "      <td>1996</td>\n",
       "      <td>1424</td>\n",
       "      <td>230</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True            0       1      2      3     4     5     6    7   8  9      All\n",
       "Predicted                                                                     \n",
       "0          501209       0      0      0     0     0     0    0   0  0   501209\n",
       "1               0  422498      0      0     0     0     0    0   0  0   422498\n",
       "2               0       0  47622      0     0     0     0    0   0  0    47622\n",
       "3               0       0      0  21121     0     0     0    0   0  0    21121\n",
       "4               0       0      0      0  3885     0     0    0   0  0     3885\n",
       "5               0       0      0      0     0  1836     0    0   4  0     1840\n",
       "6               0       0      0      0     0     0  1424    0   0  0     1424\n",
       "7               0       0      0      0     0     0     0  230   0  0      230\n",
       "8               0       0      0      0     0   152     0    0   8  0      160\n",
       "9               0       0      0      0     0     8     0    0   0  3       11\n",
       "All        501209  422498  47622  21121  3885  1996  1424  230  12  3  1000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_pred, y_test, rownames=['Predicted'], colnames=['True'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that the model is bad at predicting flushes and above (The stronger hands). We have concluded that\n",
    "the Decision Tree Classifer is decent at prediciting weaker hands but continuously struugles in predicitng with stronger ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Fold\n",
      "2-Fold\n",
      "3-Fold\n",
      "4-Fold\n",
      "5-Fold\n",
      "6-Fold\n",
      "7-Fold\n",
      "8-Fold\n",
      "9-Fold\n",
      "10-Fold\n",
      "0.9982007197121152\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.ensemble.RandomForestClassifier(criterion='gini', n_estimators=10, random_state=111, n_jobs=4)\n",
    "# cross_validation(alg, X_train, Y_train)\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "    curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    acc.append(curr)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Random Forest Classifier, we get a 99.84% accuracy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Fold\n",
      "2-Fold\n",
      "3-Fold\n",
      "4-Fold\n",
      "5-Fold\n",
      "6-Fold\n",
      "7-Fold\n",
      "8-Fold\n",
      "9-Fold\n",
      "10-Fold\n",
      "0.5527788884446222\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(random_state=0, solver=\"lbfgs\", max_iter=100, multi_class=\"ovr\")\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "matrix = None\n",
    "first = True\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('{}-Fold'.format(i))\n",
    "    fX_train, fX_test = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    fy_train, fy_test = y_train[train_index], y_train[test_index]\n",
    "    clf.fit(fX_train, fy_train)\n",
    "    fy_pred = clf.predict(fX_test)\n",
    "    curr = accuracy_score(fy_test, fy_pred, normalize=True)\n",
    "    acc.append(curr)\n",
    "    i = i+1\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-Fold CV for LogisitcRegression is not that great compared to other models. Sitting at 55.27% accuracy, other models simply outperform this one by 40+ percentage points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network: Here we have excellent results, accuracies close to 100%. By changing the hidden-layers, we approach 99.95% at 150,100,50. This is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLPClassifier : '' 0.999591\n"
     ]
    }
   ],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "   diagonal_sum = confusion_matrix.trace()\n",
    "   sum_of_all_elements = confusion_matrix.sum()\n",
    "   return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "classifier = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=1000,activation = 'relu',solver='adam',random_state=1).fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy of MLPClassifier : ''\", accuracy(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZCb933f8fcXx2Iv7K64i93lJfEQD9GORCuMbEuOzziR5CSMM00qJU0cN41GreyxZ9Kp7bRx02SaacaTNIljW1VcJ81l2fGpeFSprh3ZqWzFpE6LIimRFCWuyD147o3z2z/wYAkulyRIAgvgwec1g8E+Dx4CXy2pz/Pgdz3m7oiISPOL1LsAERGpDgW6iEhIKNBFREJCgS4iEhIKdBGRkIjV64MHBgZ83bp19fp4EZGm9OSTTx5399RSr9Ut0NetW8fu3bvr9fEiIk3JzF650GtqchERCQkFuohISFwy0M3sc2Y2bmbPX+B1M7M/NbMDZvacmd1c/TJFRORSKrlC/0vg9ou8fgewKXjcA3zm6ssSEZHLdclAd/fvAicvcshO4K+86Amgz8xWVqtAERGpTDXa0FcDR8q2R4J95zGze8xst5ntnpiYqMJHi4hISTUC3ZbYt+QSju7+gLvvcPcdqdSSwyhFROQKVSPQR4C1ZdtrgKNVeN8l7Rud5BOP7uP0bKZWHyEi0pSqEegPAb8ajHZ5E3DG3Y9V4X2XdPj4LJ/6x4OMnJqr1UeIiDSlS84UNbPPA28HBsxsBPjPQBzA3e8HHgbuBA4As8D7a1UswGBPAoDxqXmgt5YfJSLSVC4Z6O5+9yVed+C+qlV0CYPJINAn08v1kSIiTaHpZoqmSoE+pUAXESnXdIGeiEXp64wHTS4iIlLSdIEOxWYXNbmIiJyrSQO9XU0uIiKLNGmgJ5hQoIuInKMpAz3VUwz04gAbERGBJg30wWQ7mXyB07PZepciItIwmjTQNXRRRGSxJg90DV0UESlpzkDvaQc0W1REpFxzBrqaXEREztOUgd6ViNHVFlWTi4hImaYMdCg2u+gKXUTkrKYN9FQywYTa0EVEFjRtoA8mE2pyEREp08SBriYXEZFyzRvoPQlmM3mm07l6lyIi0hCaN9AX7lykZhcREWjqQA8mF6nZRUQEaOZA79HkIhGRcs0b6GpyERE5R9MGem9HnLZYRDe6EBEJNG2gmxmp7oSaXEREAk0b6FBsR9fkIhGRouYO9GRCS+iKiASaPNA1W1REpKTJAz3Bmbks89l8vUsREam75g70YCy6RrqIiDR7oGu2qIjIgqYO9FSydIWukS4iIk0d6Jr+LyJyVlMHen9XgoihoYsiIlQY6GZ2u5ntN7MDZvbRJV7vNbN/MLNnzWyPmb2/+qWeLxoxBroT6hQVEaGCQDezKPAp4A5gG3C3mW1bdNh9wAvufhPwduAPzaytyrUuSbNFRUSKKrlCvwU44O6H3D0DPAjsXHSMA0kzM6AbOAksy62ENLlIRKSokkBfDRwp2x4J9pX7M+AG4CjwQ+BD7l5Y/EZmdo+Z7Taz3RMTE1dY8rmKN4tWoIuIVBLotsQ+X7T9U8AzwCpgO/BnZtZz3h9yf8Ddd7j7jlQqddnFLmUwmeDEdJp8YXFJIiKtpZJAHwHWlm2voXglXu79wFe86ADwMrC1OiVeXKqnnYLDiWldpYtIa6sk0HcBm8xsfdDReRfw0KJjXgXeBWBmQ8AW4FA1C72QoWBy0ZiGLopIi7tkoLt7DvgA8CiwF/iiu+8xs3vN7N7gsN8DbjWzHwLfAj7i7sdrVXS5dQNdABycmF6OjxMRaVixSg5y94eBhxftu7/s56PAT1a3tMqsH+iiLRph7+gkP3deX62ISOto6pmiAPFohI2D3ewfnap3KSIiddX0gQ5ww3CSfccU6CLS2kIR6FuGk4xOznN6NlPvUkRE6iY0gQ6wT80uItLCQhHoN6wszmFSO7qItLJQBPpgMkFfZ1xX6CLS0kIR6GbG1uEk+0Yn612KiEjdhCLQAbYO9/Di6BQFrekiIi0qRIGeZCaTZ+TUXL1LERGpi9AE+tmRLmp2EZHWFJpA3zyUxExDF0WkdYUm0LsSMa5d0amhiyLSskIT6ABbhpLsVZOLiLSoUAX61pU9HD4+w3w2X+9SRESWXbgCfThJweGlMa2NLiKtJ3SBDhrpIiKtKVSBfl1/F+3xiEa6iEhLClWgRyPG5qGkRrqISEsKVaBDcaSLmlxEpBWFL9CHkxyfzjAxla53KSIiyyp0ga610UWkVYUu0DcNdgNwcEJDF0WktYQu0FPJBMlETIEuIi0ndIFuZmwY7Fagi0jLCV2gA2xMdXFgXIEuIq0llIF+/WA3Y5Nppuaz9S5FRGTZhDLQN6aKHaOHJmbqXImIyPIJdaCrHV1EWkkoA/26/k5iEVOgi0hLCWWgx6MRru3vVMeoiLSUUAY6wPWpbg6qDV1EWkhoA33jYDevnJghmy/UuxQRkWVRUaCb2e1mtt/MDpjZRy9wzNvN7Bkz22Nm36lumZdvY6qbbN45cnK23qWIiCyLSwa6mUWBTwF3ANuAu81s26Jj+oBPAz/r7q8DfqEGtV6WjakuADW7iEjLqOQK/RbggLsfcvcM8CCwc9ExvwR8xd1fBXD38eqWefk2Bot0qWNURFpFJYG+GjhStj0S7Cu3GbjGzB4zsyfN7FeXeiMzu8fMdpvZ7omJiSuruEI97XEGkwkNXRSRllFJoNsS+3zRdgz4UeA9wE8Bv21mm8/7Q+4PuPsOd9+RSqUuu9jLtTGlRbpEpHVUEugjwNqy7TXA0SWOecTdZ9z9OPBd4KbqlHjlNg52cXB8GvfF5x8RkfCpJNB3AZvMbL2ZtQF3AQ8tOubrwI+bWczMOoE3AnurW+rl25jqZnI+x/HpTL1LERGpudilDnD3nJl9AHgUiAKfc/c9ZnZv8Pr97r7XzB4BngMKwGfd/flaFl6J0pouB8anSSUTda5GRKS2LhnoAO7+MPDwon33L9r+BPCJ6pV29a4vux3dmzf217kaEZHaCu1MUYDhnnY626LqGBWRlhDqQI9EjA2pLk0uEpGWEOpAh2DooiYXiUgLaIlAf+30HLOZXL1LERGpqdAHeqljVLejE5GwC32g63Z0ItIqQh/o1/V3YgYvH9cVuoiEW+gDvT0eZXVfh5pcRCT0Qh/oAOsHunSFLiKh1xKBviEIdC3SJSJh1hqBnupmOp1jYipd71JERGqmJQJ9/UDxdnSH1OwiIiHWUoGudnQRCbOWCPTVfR20xSIc0lh0EQmxlgj0SMRY36+RLiISbi0R6FBsdlEbuoiEWcsE+oZUF6+emCWbL9S7FBGRmmiZQF8/0EWu4Iycmqt3KSIiNdEygb4hVRrpoo5REQmn1gn0AS2jKyLh1jKBfk1XG32dcXWMikhotUygQ7Cmi67QRSSkWirQ1w90c0ht6CISUi0V6BtSXYxNpplJ6/6iIhI+rRXoWtNFREKspQJ9fUqrLopIeLVUoK/r7yreX1QdoyISQi0V6O3xKKt6OzS5SERCqaUCHYodo2pyEZEwarlAXx+MRdf9RUUkbFou0DcMdDGVznF8OlPvUkREqqrlAn19qrSmi9rRRSRcKgp0M7vdzPab2QEz++hFjvsxM8ub2b+oXonVtUE3jBaRkLpkoJtZFPgUcAewDbjbzLZd4Lg/AB6tdpHVtLqvg862KPtHp+pdiohIVVVyhX4LcMDdD7l7BngQ2LnEcR8EvgyMV7G+qotEjE1DSV4cU6CLSLhUEuirgSNl2yPBvgVmthp4L3D/xd7IzO4xs91mtntiYuJya62arUNJXaGLSOhUEui2xL7FY/7+GPiIu+cv9kbu/oC773D3HalUqtIaq27zcJITMxkmptJ1q0FEpNpiFRwzAqwt214DHF10zA7gQTMDGADuNLOcu3+tKlVW2dbhJAAvjk2RSibqXI2ISHVUcoW+C9hkZuvNrA24C3io/AB3X+/u69x9HfAl4N81apgDbB4qBvo+NbuISIhc8grd3XNm9gGKo1eiwOfcfY+Z3Ru8ftF280aUSibo72rjRQW6iIRIJU0uuPvDwMOL9i0Z5O7+a1dfVu1tGU6yTyNdRCREWm6maMnmoSQvjU1RKGhNFxEJh5YN9K3DSWYzeUZOzdW7FBGRqmjZQN8yXOoYnaxzJSIi1dGygb5p6OzQRRGRMGjZQO9OxFi7okNDF0UkNFo20AG2aAkAEQmR1g704SQvH58hnbvoigUiIk2hxQO9h1zBOTShtdFFpPm1dqCrY1REQqSlA31Dqot41NQxKiKh0NKBHo9G2JjqVseoiIRCSwc6FJcAUKCLSBi0fKBvGU7y2uk5puaz9S5FROSqKNAXOkan61yJiMjVUaBrTRcRCYmWD/Q113Qw0N3GrpdP1rsUEZGr0vKBbma8eeMA3zt4AnetjS4izavlAx3gto39jE+lOTihdnQRaV4KdOC26wcAePzAiTpXIiJy5RTowNoVnaxd0cHjB47XuxQRkSumQA/ctnGAJw6dIK97jIpIk1KgB269foDJ+RzPv3am3qWIiFwRBXrgzRv6AXj8oJpdRKQ5KdADqWSCLUNJvn9QHaMi0pwU6GVuvb6fXYdP6g5GItKUFOhlbts4wHy2wFOvnK53KSIil02BXuaNG1YQjRjfUzu6iDQhBXqZZHucG9f0ajy6iDQlBfoit20c4NmRM1ofXUSajgJ9kVuv7ydfcH6g1RdFpMko0Be5+dpr6IhH+b97x+tdikhVzaRzfO3p17SqaIgp0Bdpj0e580dW8g/PHmU2k6t3OSJV843njvLhLzyjVUVDrKJAN7PbzWy/mR0ws48u8fovm9lzweN7ZnZT9UtdPnfdspbpdI6Hfzha71JEqubYmflzniV8LhnoZhYFPgXcAWwD7jazbYsOexl4m7vfCPwe8EC1C11OO667hg2pLr6w69V6lyJSNWOTaQBGFeihVckV+i3AAXc/5O4Z4EFgZ/kB7v49dz8VbD4BrKlumcvLzPiXO9ay6/ApDozr66mEw9jk/DnPEj6VBPpq4EjZ9kiw70J+HfjfS71gZveY2W4z2z0xMVF5lXXw8zevIRYxvrj7yKUPFmkCpSAfVaCHViWBbkvsW7Kb3MzeQTHQP7LU6+7+gLvvcPcdqVSq8irrIJVM8K4bBvnykyNkcoV6lyNy1c42uaTrXInUSiWBPgKsLdteAxxdfJCZ3Qh8Ftjp7qFYsvCuH7uWEzMZvr1vrN6liFyVbL7AiZlikI9P6Qo9rCoJ9F3AJjNbb2ZtwF3AQ+UHmNm1wFeAX3H3F6tfZn28dXOK4Z52HtylZhdpbsen07hDLGLqFA2xSwa6u+eADwCPAnuBL7r7HjO718zuDQ77ONAPfNrMnjGz3TWreBlFI8Yv7FjDd16c4OjpuXqXI3LFSiG+dWWS49Npcnk1I4ZRRePQ3f1hd9/s7hvd/b8G++539/uDn/+Nu1/j7tuDx45aFr2cfnHHWtzhb//5lXqXInLFSu3nN67po+AwMa129DDSTNFLWLuik/fcuJLP/tPLHDk5W+9yRK5Iqd38pjW9gMaih5UCvQL/6T03EI0Yv/PQnnqXInJFxibniUaMbSt7F7YlfBToFVjZ28GHf2IT39o3zjdf0IgXaT5jk2kGkwmGe9sXtiV8FOgVev9t69k81M3vPLSHuUy47jmaLzh/9M0XOXZGHb9hNTY5z1BPO/1dbcSjpslFIaVAr1A8GuF3d76e107P8enHDtS7nKrae2ySP/3WS3z16dfqXYrUSDHQE0QixmCynTG1oYeSAv0yvGlDP+99w2r+x3cO8fLxmXqXUzX7RqcAeDF4lvAZm0wz1FNsbhnqSegKPaQU6JfpY3duJRGL8JEvPReasbz7RyeLz2NaiCyM5rN5zsxlFwJ9uLddgR5SCvTLNJhs53d/7nX84PBJPvntcDS9lK7QD45Ph+YkJWeNBx2gg8kEAEM97Qv7ZPk9/MNjNVvFVYF+Bd77hjX8/M2r+eS3X+L7B5t/2Zr9o1N0xKNk8gUOn9BY+7ApXY2XRrgM9bQznc4xndYduZZbJlfgQw8+zZefGqnJ+yvQr9Dv7Xw91/V38eEvPM2JJp51d2omw/hUmndvGwLgxTG1o4dNacz5QpNL8KzJRcvv4MQ02byzdThZk/dXoF+hrkSMT979Bk7NZPn3f/9s0954t9Tc8p4bV2JWvFqXcFkI9OTZK/Ty/bJ89gX9VdtW9tTk/RXoV+H1q3v5rTu38o/7J/j0YwfrXc4VKXWIbl/bx7r+Ll2hh9D4VJpELEJPRww42/SiK/Tlt/fYFG3RCOsHumry/rGavGsLed+t69h1+BSfeHQ/APe94/o6V3R59o9N0dcZZzCZYPNQN/sV6KFTmlRkVrxXzUKTi67Ql93eY5NsGuomFq3NtbSu0K+SmfHHd21n5/ZVfOLR/fzBI/uaqvll3+gUW4aSmBlbhpIcPj7DfDZcM2Fb3eiZ+YUQB+hoi9LTHmNcgb7s9h6b4oYaNbeAAr0q4tEIf/SL27n7lmv5zGMH+fjX91AoNH6oFwrOi6NTCx00m4eTFLzYcSPhMT6VZrAncc6+oR6NRV9uE1Npjk+na9YhCgr0qolGjN9/7+u5560b+OsnXuG+v3uKUzOZepd1Ua+dnmMmk2fLcPGKYctQ8R+a2tHDw90XmlzKFScXNe/orGZUGnCgK/QmYWZ87I6t/NadW/nmC2O8+79/h0eeH613WRdUGuGyJbhiWDfQRTxq7B/VFXpYTKdzzGbyDC1xha71XJbX3mPFAQi6Qm8iZsY9b93IQx94C0M97dz7N0/ywc8/zckGvFovjXApBXo8GmFjqltX6CFSWib3vCv0nnYmptPkm6BpMCz2jk4ymEzQ35249MFXSIFeI9tW9fC1+27jN9+9mUeeP8Y7//Ax/vr7hxtqav2+0SnWXNNBd+LsYKctw0mNRQ+RxZOKSoZ628kXvKknxTWbfTXuEAUFek3FoxE++K5NfOODP84Nwz389tf38NOf/H8Ns1zA/rIO0ZLNQ0leOz3H1Hy2TlVJNV0o0DV0cXll8wUOjE+zdWXtmltAgb4stgwn+bvfeCOf+eWbmZrPcfefP8G//stdPPL8MdK5+gwRTOfyHDo+s9DcslBr0DH6Uo0WD5LlNbZoYa4STf9fXocmZsjkC9wwXNsrdE0sWiZmxh0/spJ3bB3kz797iP/1/Vf49r5xetpjvOfGVbxr6yD93W30dbbR2xGntyNONGI1q+fg+Az5gi+McCkpBfyLo1PcfO01Nft8WR5jk/MkEzG6Euf+r17qJNX0/+VR6hCtdZOLAn2ZtcejfPBdm/i3b9/I4wdP8NWnRvja06/x+R+8es5xvR1x7r7lWt5363Ws7O2oeh37x5bucV/d10FnW1QzRkNifGr+vDHoAP3dCaIR3YpuuewdnSQeNTakajPlv0SBXiexaIS3bU7xts0pZtI59o1OMTmX5cxcltOzGX5w+CQPfPcgn/2nQ/zMTav4lTdfx42re6s2ZXjf6BTxqJ23pkQkYmwaSmqkS0iU36moXDRiDCYTjJ5Rp+hy2HdsiusHk8RrNOW/RIHeALoSMX70unObN37ttvUcOTnLXzx+mC/sepWvPv0a7fEIr1vVy01r+njdqh5W9XUw3NvOcE87HW3Ry/rM/aNTbEx1L/kPbMtQN9/eN3FV/03SGEbPzPPG9SuWfG2op53xKV2hL4e9xyZ5y6aBmn+OAr2BrV3Rycd/Zhsf+olNPLZ/nOdGzvDskdP83Q9eYT577vDHnvbYQvt7X2ecazrb2DKc5HWrenjdql5SizrF9o9OXfB/9M1DSb64e4QT0+majpmV2nL3oMnl/Ct0KHaMapmH2jsxnWZ8Kl3zDlFQoDeF3o44O7evZuf21QDkgjsLjU3Oc+zMPGOT84xPznM6aLI5M5fl5eMzPPTs0YX3GOhOMNSTYEVXseP12Jn58zpES0odo0+9eprXr+4hnS2QzhXo726jv6ttYdU+aWynZrNk837eLNGS4d52Hj94fJmraj3LMeW/RIHehGLRCNcPdnP9YPdFj5ucz/LC0Un2HJ1k/+gkJ6YznJzNcOTkLEM9Cd5y/dJfAUtDF3/jr3af91oyEeO6gU6u6+9iRWcbiViE9niU9ngEM8PdKTgU3IlHI3S2Relsi9LRFqOrLUpHW5SuthhdieK+juDPtseiRMpG9ZRWrNTJ48pdaAx6yWBPgqn5HLOZHJ1tioJaeaE05b/GY9BBgR5qPe1x3rShnzdt6L+sPzfY086f/dIbOD6VJhEEbjwaYWIqzSsnZnn5+Ax7XjvD5HyO+Wye+Wyeaswgj0WMQnBCADCDjni0+GiL0h6P0haN0BYLHtEIkYgRMYiYEY3YOcfHIsap2SynZjOcnMkwNZ+lOxGjpyNOT3ucZHuMSMSw4LOiZiTbi01WpearRCxCLFJ871g0QjxqxCLF53g0QjRiRCJG1Ip1lI6LRYxY1GiLRs47Kbk70+kcp2ezFNzpbIsVT3rxc09qF5PJFTg9l6FQgFQyseQQ17OBfoEr9CDoP/LlH/Ijq3vYNJhkY6qbgWQbHfGoTqZVsm90ioHuBAPL0HypQJcl/fSNqyo+1t3J5h3HiZgRsWJIZgsFZtN5ZrN5ZoNFooqP4s9zmTzzufzCz9l8gWjEsODPF9yZy+SZyxYf89k8mVyx+SeTKzCTyeHBt4GCO7m8Mx8cO5fJkys4fR1xVnS3cU1nG6v62plJ55mcz3L09BxT8zkK7riDA/mCMzWfrcrJqVx7PBJ8E4kGQZy94BoqbaUTiBnRqJ09mUSKJ49cvsCZuSwzmbMT0mIRY1VfB6v7OljR3cZcJs90OsexM3MADCaXvkK/deMAP75pgCcOneAfyprnSnVcE/TFdCViC9+0OttitEUjxGPFE1pbNEJHW5TuYKx7V6L4rSsRixQf8SgRY+F3DBCP2sLvoyMeJR6LnHNSjgQnx2qcUDz4+630RHkl7z+XzXNyJsOJ6QwnZtKcns3S2xFnZW8HK3vb2XtskhuW4eocFOhSBWZGW+z8/2ESkSiJWJRmmp5UKDhT6RxnZrOcnsuQzRfI5p18wcnmCwvP2fzZ7dK3inyheFyu4OTyBXIFJ50rFE8ywYmpLRahr6MYlL2dcaJmzGbzzGVyzKTzpHOFhZNTvlAgW3AKwXvmC8UTZl9nnL6g8xszjp6e47VTc4ycmmXv0Uk6E8VmrU2DSd59wzCr+5aexzDc285f//obATg9m+HA+DSHJmY4MZPh9GyGU7MZTs9mmQ1OEBNTaWYyObK54n97Jl9YOMHWilnxhBUPvvUUT3iR4JtQ8QSAUzzJB/Vkg9996e8DIGLFpsp48I2q/O+p4Cx84yq9f9HZk27ppBqLFk84c5k8M+kcM5lcRRcA97x1Qw1+O+erKNDN7HbgT4Ao8Fl3/2+LXrfg9TuBWeDX3P2pKtcqUnORiC3M1L2WznqXs2z6OtvYsW4FO9YtPfLpYnL5AjOlgEvnmM8WSOeKJ6d0Lo+XNaEBZEvfpIKTXC7v5L0YvoVC8eToBM9+NnhLJ9HiiRTyhWJwQ/EbRSJohotHIwvNXsVvfJDLO9lCIThRevG1qBGPFL8dZAtONjgZZPK+UKtRjPVCwYMTe4G8Q0c8QmdbjO5EjM5ElP6uNvq7Eguzvc/MZTl2eo6jZ+Y5Pp3m7h+79ur/kipwyUA3syjwKeDdwAiwy8wecvcXyg67A9gUPN4IfCZ4FpGQi0Uj9HZE6O2I17uUhrJ9bd+yf2Yl05ZuAQ64+yF3zwAPAjsXHbMT+CsvegLoM7OVVa5VREQuopJAXw0cKdseCfZd7jEiIlJDlQT6Ut3Di7sBKjkGM7vHzHab2e6JCU0tFxGppkoCfQRYW7a9Bjh6Bcfg7g+4+w5335FKpS63VhERuYhKAn0XsMnM1ptZG3AX8NCiYx4CftWK3gSccfdjVa5VREQu4pKjXNw9Z2YfAB6lOGzxc+6+x8zuDV6/H3iY4pDFAxSHLb6/diWLiMhSKhqH7u4PUwzt8n33l/3swH3VLU1ERC6H7ikqIhISVlrVbtk/2GwCeOUK//gA0OjrfqrGq9fo9UHj19jo9UHj19ho9V3n7kuOKqlboF8NM9vt7jvqXcfFqMar1+j1QePX2Oj1QePX2Oj1lVOTi4hISCjQRURColkD/YF6F1AB1Xj1Gr0+aPwaG70+aPwaG72+BU3Zhi4iIudr1it0ERFZRIEuIhISTRfoZna7me03swNm9tF61wNgZp8zs3Eze75s3woz+6aZvRQ81+1ObGa21sz+0cz2mtkeM/tQA9bYbmY/MLNngxr/S6PVGNQTNbOnzewbDVrfYTP7oZk9Y2a7G61GM+szsy+Z2b7g3+ObG6y+LcHvrvSYNLMPN1KNF9NUgV5296Q7gG3A3Wa2rb5VAfCXwO2L9n0U+Ja7bwK+FWzXSw74TXe/AXgTcF/we2ukGtPAO939JmA7cHuw0Fsj1QjwIWBv2Xaj1QfwDnffXjZ2upFq/BPgEXffCtxE8XfZMPW5+/7gd7cd+FGKa1N9tZFqvKjiXbGb4wG8GXi0bPtjwMfqXVdQyzrg+bLt/cDK4OeVwP5611hW29cp3lKwIWsEOoGnKN7GsGFqpLgs9LeAdwLfaMS/Z+AwMLBoX0PUCPQALxMMxmi0+pao9yeBxxu5xsWPprpCp7nujDTkwRLCwfNgnesBwMzWAW8A/pkGqzFozngGGAe+6e6NVuMfA/8BKL/NfSPVB8Uby/wfM3vSzO4J9jVKjRuACeAvgmarz5pZVwPVt9hdwOeDnxu1xnM0W6BXdGckWZqZdQNfBj7s7pP1rmcxd8978avuGuAWM3t9vWsqMbOfBsbd/cl613IJt7n7zRSbJe8zs7fWu6AyMeBm4DPu/gZghgZtugju/fCzwN/Xu5bL0WyBXtGdkRrEWOlG2cHzeD2LMbM4xTD/W3f/SrC7oWoscffTwGMU+yUapcbbgJ81s8MUb5T+TjP7mwaqDwB3Pxo8j1Ns+72FxqlxBBgJvnkBfIliwDdKfeXuAJ5y97FguxFrPE+zBXold2c6GusAAAENSURBVE9qFA8B7wt+fh/Fduu6MDMD/iew193/qOylRqoxZWZ9wc8dwE8A+2iQGt39Y+6+xt3XUfx39213/1eNUh+AmXWZWbL0M8U24OdpkBrdfRQ4YmZbgl3vAl6gQepb5G7ONrdAY9Z4vno34l9BR8WdwIvAQeA/1rueoKbPA8eALMWrkF8H+il2oL0UPK+oY31vodg09RzwTPC4s8FqvBF4OqjxeeDjwf6GqbGs1rdztlO0Yeqj2Eb9bPDYU/r/o8Fq3A7sDv6evwZc00j1BTV2AieA3rJ9DVXjhR6a+i8iEhLN1uQiIiIXoEAXEQkJBbqISEgo0EVEQkKBLiISEgp0EZGQUKCLiITE/wc4WH2AYz6SkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss graph for MLP(128,64,10)\n",
    "loss_values = classifier.loss_curve_\n",
    "plt.plot(loss_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss graph for MLP(150,100,50)\n",
    "loss_values = classifier.loss_curve_\n",
    "plt.plot(loss_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss graph for MLP(200,150,100)\n",
    "loss_values = classifier.loss_curve_\n",
    "plt.plot(loss_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Accuracy of MLPClassifier : '' 99.66% with 128,64,10\n",
    "\n",
    "Accuracy of MLPClassifier : '' 99.95% with 150,100,50\n",
    "\n",
    "Accuracy of MLPClassifier : '' 99.89% with 200,150,100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are a few neural network implementations for this dataset. The one we found the most interesting is linked here:https://rasbt.github.io/coral_pytorch/tutorials/poker/#2-equipping-mlp-with-coral-layer. The MLP classification used here is more simple and also achieves a high accuracy rate https://medium.com/swlh/dumbly-teaching-a-dumb-robot-poker-hands-for-dummies-or-smarties-f3da161ead65."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
